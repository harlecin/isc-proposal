# The Problem
<!-- 
Outlining the issue / weak point / problem to be solved by this proposal. This should be a compelling section that sets the reader up for the next section - the proposed solution!

It is important to cover:

 - [ ] What the problem is
 - [ ] Who it affects
 - [ ] Have there been previous attempts to resolve the problem
 - [ ] Why it should be tackled
-->


## Problem Definition

R is a great language for rapid prototyping and experimentation, but putting an R model in production is still more complex and time-consuming than it needs to be. With the growing popularity of serverless computing frameworks we see a a huge chance to allow R developers to easily deploy their code into production in a platform independent manner.

Putting an R model in production usually requires two environments:

1. a training environment with strong CPUs/GPUs
2. a scoring environment that reads models and scores new data

Training can usually be handled with batch jobs and there are various offerings available that allow developers to run workloads with custom runtimes such as R. Most of the time this involves building a Docker image. Popular platforms for batch computing in the cloud include:

- Azure Batch
- AWS Batch
- Google Compute Engine

While the support for Docker images allows us to run workloads on any provider that supports Docker there is no consistent API for:

- defining compute pool resources (e.g. 3 nodes, ubuntu with 2 cores each)
- defining jobs
- defining tasks for a job and
- defining task schedules.

This means that R developers still need to spend quite some time learning the APIs of whichever cloud provider they use. In many cases this also means having to work with JavaScript, Python, etc. to interact with the respective APIs. Packages such as [`doAzureParallel`](https://github.com/Azure/doAzureParallel) already try to bridge the gap for R users who want to run workloads on Azure Batch clusters from the comfort of their R session.

While serverless batch computing with R is already doable, deploying serverless R functions on platforms such as Azure Functions or AWS Lambda is at the time of this writing very complex/not possible.

Leveraging serverless compute platforms such as Azure Functions or AWS Lambda would have tremendous benefits to easily integrate R into production workloads for scoring. Since scoring is usually computationally cheap and only involves ingesting new data to score and loading a trained model, it provides an excellent fit for serverless functions frameworks and would provide among others the following benefits:

- Developers can focus on coding and not on the underlying infrastructure.
- Scaling is automatically handled for them.
- Only pay for resources they acutally need.
- Setting up triggers to serve predictions using timers or events.

However, as already said, deploying serverless functions with R is currently quite complex for R users. The problem with the current cloud offerings is the limited range of supported languages. Usually only Javascript, Java, C#/F#, Go and Python are supported for serverless functions:

- [Azure](https://docs.microsoft.com/en-us/azure/azure-functions/supported-languages): C#, JavaScript (Node.js), F#, Java, Python
- [AWS](https://aws.amazon.com/lambda/faqs/): JavaScript (Node.js), Python, Java, C# and Go
- [Google Cloud](https://cloud.google.com/functions/docs/writing/): JavaScript (Node.js), Python

Adding additional language runtimes such as R are possible in some cases and we believe that this would be a first step to give R users the option to leverage the power and ease-of-use of serverless computing.

<!--INSERT PICTURE SHOWING ARCHITECTURE-->


